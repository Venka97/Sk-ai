{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EDGE_CROP = 16\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'SIMPLE'\n",
    "# downsampling inside the network\n",
    "NET_SCALING = (1, 1)\n",
    "# downsampling in preprocessing\n",
    "IMG_SCALING = (2, 2)\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT = 600\n",
    "# maximum number of steps_per_epoch in training\n",
    "MAX_TRAIN_STEPS = 150\n",
    "AUGMENT_BRIGHTNESS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import montage2d as montage\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "\n",
    "import gc; gc.enable() # memory is tight\n",
    "\n",
    "from skimage.morphology import label\n",
    "def multi_rle_encode(img):\n",
    "    labels = label(img[:, :, 0])\n",
    "    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "    #if isinstance(in_mask_list, list):\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return np.expand_dims(all_masks, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_dir = '/home/ubuntu/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_dir = os.path.join(ship_dir, 'train')\n",
    "test_image_dir = os.path.join(ship_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = pd.read_csv(os.path.join(ship_dir,'train_ship_segmentations.csv'))\n",
    "print(masks.shape[0], 'masks found')\n",
    "print(masks['ImageId'].value_counts().shape[0])\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "# some files are too small/corrupt\n",
    "unique_img_ids['file_size_kb'] = unique_img_ids['ImageId'].map(lambda c_img_id: \n",
    "                                                               os.stat(os.path.join(train_image_dir, \n",
    "                                                                                    c_img_id)).st_size/1024)\n",
    "#print(unique_img_ids['file_size_kb']<50)\n",
    "unique_img_ids = unique_img_ids[unique_img_ids['file_size_kb']>50] # keep only 50kb files\n",
    "unique_img_ids['file_size_kb'].hist()\n",
    "masks.drop(['ships'], axis=1, inplace=True)\n",
    "unique_img_ids.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                 test_size = 0.2, #Changed the ratio to 0.2 \n",
    "                 stratify = unique_img_ids['ships'])\n",
    "train_df = pd.merge(masks, train_ids)\n",
    "valid_df = pd.merge(masks, valid_ids)\n",
    "print(train_df.shape[0], 'training masks')\n",
    "print(valid_df.shape[0], 'validation masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ships'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['grouped_ship_count'] = train_df['ships'].map(lambda x: (x+2)//3)\n",
    "balanced_train_df = train_df.groupby('grouped_ship_count').apply(lambda x: x.sample(1500))\n",
    "balanced_train_df['ships'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_gen(in_df, batch_size = BATCH_SIZE):\n",
    "    all_batches = list(in_df.groupby('ImageId'))\n",
    "    out_rgb = []\n",
    "    out_mask = []\n",
    "    while True:\n",
    "        np.random.shuffle(all_batches)\n",
    "        for c_img_id, c_masks in all_batches:\n",
    "            rgb_path = os.path.join(train_image_dir, c_img_id)\n",
    "            c_img = imread(rgb_path)\n",
    "            c_mask = masks_as_image(c_masks['EncodedPixels'].values)\n",
    "            if IMG_SCALING is not None:\n",
    "                c_img = c_img[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "                c_mask = c_mask[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "            out_rgb += [c_img]\n",
    "            out_mask += [c_mask]\n",
    "            if len(out_rgb)>=batch_size:\n",
    "                yield np.stack(out_rgb, 0)/255.0, np.stack(out_mask, 0)\n",
    "                out_rgb, out_mask=[], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = make_image_gen(balanced_train_df)\n",
    "train_x, train_y = next(train_gen)\n",
    "print('x', train_x.shape, train_x.min(), train_x.max())\n",
    "print('y', train_y.shape, train_y.min(), train_y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (30, 10))\n",
    "batch_rgb = montage_rgb(train_x)\n",
    "batch_seg = montage(train_y[:, :, :, 0])\n",
    "ax1.imshow(batch_rgb)\n",
    "ax1.set_title('Images')\n",
    "ax2.imshow(batch_seg)\n",
    "ax2.set_title('Segmentations')\n",
    "ax3.imshow(mark_boundaries(batch_rgb, \n",
    "                           batch_seg.astype(int)))\n",
    "ax3.set_title('Outlined Ships')\n",
    "fig.savefig('overview.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x, valid_y = next(make_image_gen(valid_df, VALID_IMG_COUNT))\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "dg_args = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 45, \n",
    "                  width_shift_range = 0.4, \n",
    "                  height_shift_range = 0.4, \n",
    "                  shear_range = 0.01,\n",
    "                  zoom_range = [0.9, 1.25], \n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = True,\n",
    "                  fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last')\n",
    "# brightness can be problematic since it seems to change the labels differently from the images \n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args[' brightness_range'] = [0.5, 1.5]\n",
    "image_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args.pop('brightness_range')\n",
    "label_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "def create_aug_gen(in_gen, seed = None):\n",
    "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
    "    for in_x, in_y in in_gen:\n",
    "        seed = np.random.choice(range(9999))\n",
    "        # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n",
    "        g_x = image_gen.flow(255*in_x, \n",
    "                             batch_size = in_x.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "        g_y = label_gen.flow(in_y, \n",
    "                             batch_size = in_x.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "\n",
    "        yield next(g_x)/255.0, next(g_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_gen = create_aug_gen(train_gen)\n",
    "t_x, t_y = next(cur_gen)\n",
    "print('x', t_x.shape, t_x.dtype, t_x.min(), t_x.max())\n",
    "print('y', t_y.shape, t_y.dtype, t_y.min(), t_y.max())\n",
    "# only keep first 9 samples to examine in detail\n",
    "t_x = t_x[:9]\n",
    "t_y = t_y[:9]\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "ax1.imshow(montage_rgb(t_x), cmap='gray')\n",
    "ax1.set_title('images')\n",
    "ax2.imshow(montage(t_y[:, :, :, 0]), cmap='gray_r')\n",
    "ax2.set_title('ships')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double-conv U-net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add skip-connections and remove a batch-norm layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "def upsample_conv(filters, kernel_size, strides, padding):\n",
    "    return layers.Conv2DTranspose(filters, kernel_size, strides=strides, padding=padding)\n",
    "def upsample_simple(filters, kernel_size, strides, padding):\n",
    "    return layers.UpSampling2D(strides)\n",
    "\n",
    "if UPSAMPLE_MODE=='DECONV':\n",
    "    upsample=upsample_conv\n",
    "else:\n",
    "    upsample=upsample_simple\n",
    "    \n",
    "input_img = layers.Input(t_x.shape[1:], name = 'RGB_Input')\n",
    "pp_in_layer = input_img\n",
    "if NET_SCALING is not None:\n",
    "    pp_in_layer = layers.AvgPool2D(NET_SCALING)(pp_in_layer)\n",
    "    \n",
    "pp_in_layer = layers.GaussianNoise(GAUSSIAN_NOISE)(pp_in_layer)\n",
    "pp_in_layer = layers.BatchNormalization()(pp_in_layer)\n",
    "\n",
    "ic1 = layers.Conv2D(32, (3, 3),activation=None,padding='same') (pp_in_layer)\n",
    "b1 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (ic1)\n",
    "#a1 = layers.Activation('relu') (b1)\n",
    "a1 = layers.ELU()(b1)\n",
    "c1 = layers.Conv2D(32, (3, 3), activation=None, padding='same') (a1)\n",
    "#b1 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(c1)\n",
    "#a1 = layers.Activation('relu') (b1)\n",
    "ad1 = layers.add([ic1,c1])\n",
    "a1 = layers.ELU()(ad1)\n",
    "d1 = layers.Dropout(0.1) (a1)\n",
    "\n",
    "p1 = layers.MaxPooling2D((2, 2)) (d1)\n",
    "\n",
    "ic2 = layers.Conv2D(64, (3, 3), activation=None, padding='same') (p1)\n",
    "b2 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (ic2)\n",
    "#a2 = layers.Activation('relu') (b2)\n",
    "a2 = layers.ELU()(b2)\n",
    "c2 = layers.Conv2D(64, (3, 3), activation=None, padding='same') (a2)\n",
    "#b2 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (c2)\n",
    "#a2 = layers.Activation('relu') (b2)\n",
    "ad2 = layers.add([ic2,c2])\n",
    "a2 = layers.ELU()(ad2)\n",
    "d2 = layers.Dropout(0.1) (a2)\n",
    "\n",
    "p2 = layers.MaxPooling2D((2, 2)) (d2)\n",
    "\n",
    "\n",
    "ic3 = layers.Conv2D(128, (3, 3), activation=None, padding='same') (p2)\n",
    "b3 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (ic3)\n",
    "a3 = layers.ELU()(b3)\n",
    "#a3 = layers.Activation('relu') (b3)\n",
    "c3 = layers.Conv2D(128, (3, 3), activation=None, padding='same') (a3)\n",
    "#b3 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (c3)\n",
    "ad3 = layers.add([ic3,c3])\n",
    "a3 = layers.ELU()(ad3)\n",
    "#a3 = layers.Activation('relu') (b3)\n",
    "d3 = layers.Dropout(0.1) (a3)\n",
    "\n",
    "p3 = layers.MaxPooling2D((2, 2)) (d3)\n",
    "\n",
    "\n",
    "ic4 = layers.Conv2D(256, (3, 3), activation=None, padding='same') (p3)\n",
    "b4 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (ic4)\n",
    "#a4 = layers.Activation('relu') (b4)\n",
    "a4 = layers.ELU()(b4)\n",
    "c4 = layers.Conv2D(256, (3, 3), activation=None, padding='same') (a4)\n",
    "#b4 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (c4)\n",
    "ad4 = layers.add([ic4,c4])\n",
    "a4 = layers.ELU()(ad4)\n",
    "#a4 = layers.Activation('relu') (b4)\n",
    "d4 = layers.Dropout(0.1) (a4)\n",
    "\n",
    "p4 = layers.MaxPooling2D((2, 2)) (d4)\n",
    "\n",
    "ic5 = layers.Conv2D(512, (3, 3), activation=None, padding='same') (p4)\n",
    "b5 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (ic5)\n",
    "a5 = layers.ELU()(b5)\n",
    "#a5 = layers.Activation('relu') (b5)\n",
    "c5 = layers.Conv2D(512, (3, 3), activation=None, padding='same') (a5)\n",
    "#b5 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (c5)\n",
    "ad5 = layers.add([ic5,c5])\n",
    "a5 = layers.ELU()(ad5)\n",
    "#a5 = layers.Activation('relu') (b5)\n",
    "d5 = layers.Dropout(0.1) (a5)\n",
    "p5 = layers.MaxPool2D((2, 2)) (d5)\n",
    "\n",
    "ic6 = layers.Conv2D(1024, (3, 3), activation=None, padding='same') (p5)\n",
    "b6 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (ic6)\n",
    "a6 = layers.ELU()(b6)\n",
    "#a6 = layers.Activation('relu') (b6)\n",
    "c6 = layers.Conv2D(1024, (3, 3), activation=None, padding='same') (a6)\n",
    "#b6 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (c6)\n",
    "ad6 = layers.add([ic6,c6])\n",
    "a6 = layers.ELU()(ad6)\n",
    "#a6 = layers.Activation('relu') (b6)\n",
    "d6 = layers.Dropout(0.1) (a6)\n",
    "\n",
    "# Decoder starts\n",
    "\n",
    "# Upsample+concat\n",
    "\n",
    "u7 = upsample(512, (2, 2), strides=(2, 2), padding='same') (d6)\n",
    "u7 = layers.concatenate([u7, c5])\n",
    "\n",
    "# Double-Conv Block\n",
    "ic7 = layers.Conv2D(512, (3, 3), activation=None, padding='same') (u7)\n",
    "b7 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (ic7)\n",
    "a7 = layers.ELU()(b7)\n",
    "#a7 = layers.Activation('relu') (b7)\n",
    "c7 = layers.Conv2D(512, (3, 3), activation=None, padding='same') (a7)\n",
    "#b7 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (c7)\n",
    "ad7 = layers.add([ic7,c7])\n",
    "a7 = layers.ELU()(ad7)\n",
    "#a7 = layers.Activation('relu') (b7)\n",
    "d7 = layers.Dropout(0.1) (a7)\n",
    "\n",
    "u8 = upsample(256, (2, 2), strides=(2, 2), padding='same') (d7)\n",
    "u8 = layers.concatenate([u8, c4])\n",
    "\n",
    "ic8 = layers.Conv2D(256, (3, 3), activation=None, padding='same') (u8)\n",
    "b8 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (ic8)\n",
    "a8 = layers.ELU()(b8)\n",
    "#a8 = layers.Activation('relu') (b8)\n",
    "c8 = layers.Conv2D(256, (3, 3), activation=None, padding='same') (a8)\n",
    "#b8 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (c8)\n",
    "ad8 = layers.add([ic8,c8])\n",
    "a8 = layers.ELU()(ad8)\n",
    "#a8 = layers.Activation('relu') (b8)\n",
    "d8 = layers.Dropout(0.1) (a8)\n",
    "\n",
    "u9 = upsample(128, (2, 2), strides=(2, 2), padding='same') (d8)\n",
    "u9 = layers.concatenate([u9, c3])\n",
    "\n",
    "ic9 = layers.Conv2D(128, (3, 3), activation=None, padding='same') (u9)\n",
    "b9 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (ic9)\n",
    "a9 = layers.ELU()(b9)\n",
    "#a9 = layers.Activation('relu') (b9)\n",
    "c9 = layers.Conv2D(128, (3, 3), activation=None, padding='same') (a9)\n",
    "#b9 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (c9)\n",
    "ad9 = layers.add([ic9,c9])\n",
    "a9 = layers.ELU()(ad9)\n",
    "#a9 = layers.Activation('relu') (b9)\n",
    "d9 = layers.Dropout(0.1) (a9)\n",
    "\n",
    "\n",
    "u10 = upsample(64, (2, 2), strides=(2, 2), padding='same') (d9)\n",
    "u10 = layers.concatenate([u10, c2])\n",
    "\n",
    "ic10 = layers.Conv2D(64, (3, 3), activation=None, padding='same') (u10)\n",
    "b10 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (ic10)\n",
    "a10 = layers.ELU()(b10)\n",
    "#a10 = layers.Activation('relu') (b10)\n",
    "c10 = layers.Conv2D(64, (3, 3), activation=None, padding='same') (a10)\n",
    "#b10 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (c10)\n",
    "ad10 = layers.add([ic10,c10])\n",
    "a10 = layers.ELU()(ad10)\n",
    "#a10 = layers.Activation('relu') (b10)\n",
    "d10 = layers.Dropout(0.1) (a10)\n",
    "\n",
    "u11 = upsample(32, (2, 2), strides=(2, 2), padding='same') (d10)\n",
    "u11 = layers.concatenate([u11, c1])\n",
    "\n",
    "ic11 = layers.Conv2D(32, (3, 3),activation=None,padding='same') (u11)\n",
    "b11 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001) (ic11)\n",
    "a11 = layers.ELU()(b11)\n",
    "#a11 = layers.Activation('relu') (b11)\n",
    "c11 = layers.Conv2D(32, (3, 3), activation=None, padding='same') (a11)\n",
    "#b11 = layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001)(c11)\n",
    "ad11 = layers.add([ic11,c11])\n",
    "a11 = layers.ELU()(ad11)\n",
    "#a11 = layers.Activation('relu') (b11)\n",
    "d11 = layers.Dropout(0.1) (a11)\n",
    "\n",
    "d = layers.Conv2D(1, (1, 1), activation='sigmoid') (d11)\n",
    "d = layers.Cropping2D((EDGE_CROP, EDGE_CROP))(d)\n",
    "d = layers.ZeroPadding2D((EDGE_CROP, EDGE_CROP))(d)\n",
    "if NET_SCALING is not None:\n",
    "    d = layers.UpSampling2D(NET_SCALING)(d)\n",
    "\n",
    "seg_model = models.Model(inputs=[input_img], outputs=[d])\n",
    "seg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import multi_gpu_model\n",
    "seg_model = multi_gpu_model(seg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclic Learning rate implementation for Keras from (https://www.jeremyjordan.me/nn-learning-rate/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import *\n",
    "\n",
    "class CyclicLR(Callback):\n",
    "    \"\"\"This callback implements a cyclical learning rate policy (CLR).\n",
    "    The method cycles the learning rate between two boundaries with\n",
    "    some constant frequency, as detailed in this paper (https://arxiv.org/abs/1506.01186).\n",
    "    The amplitude of the cycle can be scaled on a per-iteration or \n",
    "    per-cycle basis.\n",
    "    This class has three built-in policies, as put forth in the paper.\n",
    "    \"triangular\":\n",
    "        A basic triangular cycle w/ no amplitude scaling.\n",
    "    \"triangular2\":\n",
    "        A basic triangular cycle that scales initial amplitude by half each cycle.\n",
    "    \"exp_range\":\n",
    "        A cycle that scales initial amplitude by gamma**(cycle iterations) at each \n",
    "        cycle iteration.\n",
    "    For more detail, please see paper.\n",
    "    \n",
    "    # Example\n",
    "        ```python\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., mode='triangular')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```\n",
    "    \n",
    "    Class also supports custom scaling functions:\n",
    "        ```python\n",
    "            clr_fn = lambda x: 0.5*(1+np.sin(x*np.pi/2.))\n",
    "            clr = CyclicLR(base_lr=0.001, max_lr=0.006,\n",
    "                                step_size=2000., scale_fn=clr_fn,\n",
    "                                scale_mode='cycle')\n",
    "            model.fit(X_train, Y_train, callbacks=[clr])\n",
    "        ```    \n",
    "    # Arguments\n",
    "        base_lr: initial learning rate which is the\n",
    "            lower boundary in the cycle.\n",
    "        max_lr: upper boundary in the cycle. Functionally,\n",
    "            it defines the cycle amplitude (max_lr - base_lr).\n",
    "            The lr at any cycle is the sum of base_lr\n",
    "            and some scaling of the amplitude; therefore \n",
    "            max_lr may not actually be reached depending on\n",
    "            scaling function.\n",
    "        step_size: number of training iterations per\n",
    "            half cycle. Authors suggest setting step_size\n",
    "            2-8 x training iterations in epoch.\n",
    "        mode: one of {triangular, triangular2, exp_range}.\n",
    "            Default 'triangular'.\n",
    "            Values correspond to policies detailed above.\n",
    "            If scale_fn is not None, this argument is ignored.\n",
    "        gamma: constant in 'exp_range' scaling function:\n",
    "            gamma**(cycle iterations)\n",
    "        scale_fn: Custom scaling policy defined by a single\n",
    "            argument lambda function, where \n",
    "            0 <= scale_fn(x) <= 1 for all x >= 0.\n",
    "            mode paramater is ignored \n",
    "        scale_mode: {'cycle', 'iterations'}.\n",
    "            Defines whether scale_fn is evaluated on \n",
    "            cycle number or cycle iterations (training\n",
    "            iterations since start of cycle). Default is 'cycle'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
    "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
    "        super(CyclicLR, self).__init__()\n",
    "\n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.step_size = step_size\n",
    "        self.mode = mode\n",
    "        self.gamma = gamma\n",
    "        if scale_fn == None:\n",
    "            if self.mode == 'triangular':\n",
    "                self.scale_fn = lambda x: 1.\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'triangular2':\n",
    "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
    "                self.scale_mode = 'cycle'\n",
    "            elif self.mode == 'exp_range':\n",
    "                self.scale_fn = lambda x: gamma**(x)\n",
    "                self.scale_mode = 'iterations'\n",
    "        else:\n",
    "            self.scale_fn = scale_fn\n",
    "            self.scale_mode = scale_mode\n",
    "        self.clr_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "\n",
    "        self._reset()\n",
    "\n",
    "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
    "               new_step_size=None):\n",
    "        \"\"\"Resets cycle iterations.\n",
    "        Optional boundary/step size adjustment.\n",
    "        \"\"\"\n",
    "        if new_base_lr != None:\n",
    "            self.base_lr = new_base_lr\n",
    "        if new_max_lr != None:\n",
    "            self.max_lr = new_max_lr\n",
    "        if new_step_size != None:\n",
    "            self.step_size = new_step_size\n",
    "        self.clr_iterations = 0.\n",
    "        \n",
    "    def clr(self):\n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "        if self.scale_mode == 'cycle':\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
    "        else:\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
    "            \n",
    "    def on_batch_end(self, epoch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change base lr to 0.00001 and step size to 4\n",
    "clr = CyclicLR(base_lr=0.00001, max_lr=0.006,step_size=2*(balanced_train_df.shape[0]//BATCH_SIZE), mode='exp_range',gamma=0.99994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.losses import binary_crossentropy\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    return 1e-3*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n",
    "#Value of adam beta_2 reduced from 0.999 to 0.99f or reducing the effect of decreased gradient batches momentum,\n",
    "# Try reducing the value further to 0.9/0.98 (Xtreme)\n",
    "#Changed Adam learning rate from 1e-3 to 3e-4\n",
    "#seg_model.compile(optimizer=Adam(3e-4, decay=1e-6, beta_2=0.99), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])\n",
    "seg_model.compile(optimizer=SGD(lr=0.0003, momentum=0.9, decay=0.0, nesterov=True), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('seg_model_unet224_reducedlr')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n",
    "                                   patience=5, \n",
    "                                   verbose=1, mode='max', min_delta=0.0001, cooldown=2, min_lr=1e-6)\n",
    "early = EarlyStopping(monitor=\"val_dice_coef\", \n",
    "                      mode=\"max\", \n",
    "                      patience=20) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(BATCH_SIZE)\n",
    "step_count = min(MAX_TRAIN_STEPS, balanced_train_df.shape[0]//BATCH_SIZE)\n",
    "aug_gen = create_aug_gen(make_image_gen(balanced_train_df))\n",
    "loss_history = [seg_model.fit_generator(aug_gen, \n",
    "                             steps_per_epoch=step_count, \n",
    "                             epochs=100, \n",
    "                             validation_data=(valid_x, valid_y),\n",
    "                             callbacks=callbacks_list,\n",
    "                            workers=1 # the generator is not very thread safe\n",
    "                                       )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_loss(loss_history):\n",
    "    epich = np.cumsum(np.concatenate(\n",
    "        [np.linspace(0.5, 1, len(mh.epoch)) for mh in loss_history]))\n",
    "    fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(22, 10))\n",
    "    _ = ax1.plot(epich,\n",
    "                 np.concatenate([mh.history['loss'] for mh in loss_history]),\n",
    "                 'b-',\n",
    "                 epich, np.concatenate(\n",
    "            [mh.history['val_loss'] for mh in loss_history]), 'r-')\n",
    "    ax1.legend(['Training', 'Validation'])\n",
    "    ax1.set_title('Loss')\n",
    "\n",
    "    _ = ax2.plot(epich, np.concatenate(\n",
    "        [mh.history['true_positive_rate'] for mh in loss_history]), 'b-',\n",
    "                     epich, np.concatenate(\n",
    "            [mh.history['val_true_positive_rate'] for mh in loss_history]),\n",
    "                     'r-')\n",
    "    ax2.legend(['Training', 'Validation'])\n",
    "    ax2.set_title('True Positive Rate\\n(Positive Accuracy)')\n",
    "    \n",
    "    _ = ax3.plot(epich, np.concatenate(\n",
    "        [mh.history['binary_accuracy'] for mh in loss_history]), 'b-',\n",
    "                     epich, np.concatenate(\n",
    "            [mh.history['val_binary_accuracy'] for mh in loss_history]),\n",
    "                     'r-')\n",
    "    ax3.legend(['Training', 'Validation'])\n",
    "    ax3.set_title('Binary Accuracy (%)')\n",
    "    \n",
    "    _ = ax4.plot(epich, np.concatenate(\n",
    "        [mh.history['dice_coef'] for mh in loss_history]), 'b-',\n",
    "                     epich, np.concatenate(\n",
    "            [mh.history['val_dice_coef'] for mh in loss_history]),\n",
    "                     'r-')\n",
    "    ax4.legend(['Training', 'Validation'])\n",
    "    ax4.set_title('DICE')\n",
    "\n",
    "show_loss(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model.load_weights(weight_path)\n",
    "seg_model.save('seg_model_unet224_reducedlr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = seg_model.predict(valid_x)\n",
    "print(pred_y.shape, pred_y.min(), pred_y.max(), pred_y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "ax.hist(pred_y.ravel(), np.linspace(0, 1, 10))\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_yscale('log', nonposy='clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMG_SCALING is not None:\n",
    "    fullres_model = models.Sequential()\n",
    "    fullres_model.add(layers.AvgPool2D(IMG_SCALING, input_shape = (None, None, 3)))\n",
    "    fullres_model.add(seg_model)\n",
    "    fullres_model.add(layers.UpSampling2D(IMG_SCALING))\n",
    "else:\n",
    "    fullres_model = seg_model\n",
    "fullres_model.save('fullres_model_unet224_reducedlr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = os.listdir(test_image_dir)\n",
    "print(len(test_paths), 'test images found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, m_axs = plt.subplots(20, 2, figsize = (10, 40))\n",
    "[c_ax.axis('off') for c_ax in m_axs.flatten()]\n",
    "for (ax1, ax2), c_img_name in zip(m_axs, test_paths):\n",
    "    c_path = os.path.join(test_image_dir, c_img_name)\n",
    "    c_img = imread(c_path)\n",
    "    first_img = np.expand_dims(c_img, 0)/255.0\n",
    "    first_seg = fullres_model.predict(first_img)\n",
    "    ax1.imshow(first_img[0])\n",
    "    ax1.set_title('Image')\n",
    "    ax2.imshow(first_seg[0, :, :, 0], vmin = 0, vmax = 1)\n",
    "    ax2.set_title('Prediction')\n",
    "fig.savefig('test_predictions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from skimage.morphology import binary_opening, disk\n",
    "out_pred_rows = []\n",
    "for c_img_name in tqdm_notebook(test_paths):\n",
    "    c_path = os.path.join(test_image_dir, c_img_name)\n",
    "    c_img = imread(c_path)\n",
    "    c_img = np.expand_dims(c_img, 0)/255.0\n",
    "    cur_seg = fullres_model.predict(c_img)[0]\n",
    "    cur_seg = binary_opening(cur_seg>0.5, np.expand_dims(disk(2), -1))\n",
    "    cur_rles = multi_rle_encode(cur_seg)\n",
    "    if len(cur_rles)>0:\n",
    "        for c_rle in cur_rles:\n",
    "            out_pred_rows += [{'ImageId': c_img_name, 'EncodedPixels': c_rle}]\n",
    "    else:\n",
    "        out_pred_rows += [{'ImageId': c_img_name, 'EncodedPixels': None}]\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "submission_df = pd.DataFrame(out_pred_rows)[['ImageId', 'EncodedPixels']]\n",
    "submission_df.to_csv('submission_reducedlr.csv', index=False)\n",
    "submission_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sub_df = pd.read_csv('submission_elu_clr_resnet.csv')\n",
    "#sub_df.drop('13703f040.jpg')\n",
    "remove = ['13703f040.jpg',\n",
    " '14715c06d.jpg',\n",
    " '33e0ff2d5.jpg',\n",
    " '4d4e09f2a.jpg',\n",
    " '877691df8.jpg',\n",
    " '8b909bb20.jpg',\n",
    " 'a8d99130e.jpg',\n",
    " 'ad55c3143.jpg',\n",
    " 'c8260c541.jpg',\n",
    " 'd6c7f17c7.jpg',\n",
    " 'dc3e7c901.jpg',\n",
    " 'e44dffe88.jpg',\n",
    " 'ef87bad36.jpg',\n",
    " 'f083256d8.jpg']\n",
    "for i in remove:\n",
    "    sub_df = sub_df[sub_df.ImageId != i]\n",
    "sub_df.sample(frac = 0.001)\n",
    "#sub_df.sample(frac notnull())'14715c06d.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
